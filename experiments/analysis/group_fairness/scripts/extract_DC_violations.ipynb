{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, pickle\n",
    "from os.path import join as ojoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('attribute_values.json') as f:\n",
    "    attribute_values = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dir = ojoin('..', 'simulation_results') \n",
    "\n",
    "directories = dict()\n",
    "for approach in ('mip', 'fairim'):\n",
    "    for attribute in ('age', 'gender', 'ethnicity'):\n",
    "        directories[(approach, attribute)] = ojoin(sim_dir, approach, 'dc', attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = ojoin('..', '..', '..', '..', 'code', 'fairim', 'networks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_coverage(approach, attribute, value, graph_number):\n",
    "\n",
    "    graph_name = 'graph_spa_500_%d'%graph_number\n",
    "\n",
    "    graph_fpath = ojoin(graph_dir, '%s.pickle'%graph_name)\n",
    "    with open(graph_fpath, 'rb') as f:\n",
    "        graph = pickle.load(f)    \n",
    "\n",
    "    subgraph_nodes = [node_id for node_id, attributes in graph.nodes(data=True) \n",
    "                      if attributes[attribute] == value]\n",
    "\n",
    "    coverage_fpath = ojoin(sim_dir, approach, 'dc', attribute, 'output_%d.txt'%graph_number)\n",
    "\n",
    "    with open(coverage_fpath) as f:\n",
    "        coverage_list = [float(line) for line in f if line.strip()]\n",
    "        assert len(coverage_list) == 500\n",
    "\n",
    "    group_coverage = sum([coverage_list[i] for i in subgraph_nodes])\n",
    "    \n",
    "    return group_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dc_rhs.json') as f:\n",
    "    dc_rhs = json.load(f)\n",
    "\n",
    "rhs_dict= dict()\n",
    "for d in dc_rhs:\n",
    "    graph_number = int(d['graph_name'].split('_')[-1])\n",
    "    rhs_dict[(d['attribute'], d['value'], graph_number)] = d['DC_RHS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "for attribute in ('age', 'gender', 'ethnicity'):\n",
    "    for value in attribute_values[attribute]:\n",
    "        for graph_number in range(20):\n",
    "            info = dict(attribute=attribute, value=value, \n",
    "                        graph_name='graph_spa_500_%d'%graph_number)\n",
    "            rhs = rhs_dict[(attribute, value, graph_number)]\n",
    "            info['rhs'] = rhs\n",
    "            for approach in ('mip', 'fairim'):\n",
    "                group_coverage = get_group_coverage(approach, attribute, value, graph_number)\n",
    "                info['%s_group_coverage'%approach] = group_coverage\n",
    "                violation = 0 if group_coverage > rhs else rhs - group_coverage\n",
    "                info['%s_violation'%approach] = violation\n",
    "            stats.append(info)\n",
    "            \n",
    "with open('dc_violations.json', 'w') as f:\n",
    "    json.dump(stats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
